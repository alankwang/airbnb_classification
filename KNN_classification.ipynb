{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b1c13c80",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Prediction Problem Report (KNN: Classification)\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "    html-math-method: mathml \n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0723b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, \\\n",
    "cross_validate, GridSearchCV, RandomizedSearchCV, KFold, StratifiedKFold, RepeatedKFold, RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e86f05",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "06025554",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./datasets/train_classification.csv')\n",
    "test = pd.read_csv('./datasets/test_classification.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5d4b16",
   "metadata": {},
   "source": [
    "## 1) Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adc06dc",
   "metadata": {},
   "source": [
    "Put the data pre-processing code. You don't need to explain it. You may use the same code from last quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "06b0f388",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['has_missing'] = train.isnull().any(axis=1).astype(int)\n",
    "test['has_missing'] = test.isnull().any(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "79fa4343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to categorize the property types\n",
    "def categorize_property(property_type):\n",
    "    if 'Entire' in property_type:\n",
    "        return 'Entire Home/Apartment'\n",
    "    elif 'Private' in property_type:\n",
    "        return 'Private Room'\n",
    "    elif 'Shared' in property_type:\n",
    "        return 'Shared Accommodation'\n",
    "    elif property_type in ['Room in hotel', 'Room in boutique hotel', 'Boat']:\n",
    "        return 'Specialty Accommodations'\n",
    "    else:\n",
    "        return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "6879f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall function to clean training and test data\n",
    "def clean_data(df):\n",
    "    \n",
    "    if 'host_is_superhost' in df.columns:\n",
    "        df.host_is_superhost = df.host_is_superhost.replace({'t': 1, 'f': 0})\n",
    "        \n",
    "    # replace missing values of numeric variables wtih the median\n",
    "    numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "    df[numeric_columns] = df[numeric_columns].apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "    # replace missing values of categorical variables with the mode \n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    df[categorical_columns] = df[categorical_columns].fillna(df[categorical_columns].mode().iloc[0])\n",
    "    \n",
    "    # replace any 0 values to 1 so that it can go through log transformation\n",
    "    df['beds'] = df['beds'].replace(0, .01)\n",
    "    df['accommodates'] = df['accommodates'].replace(0, .01)\n",
    "    df['number_of_reviews'] = df['number_of_reviews'].replace(0, .01)\n",
    "    df['reviews_per_month'] = df['reviews_per_month'].replace(0, .01)\n",
    "    df['number_of_reviews_ltm'] = df['number_of_reviews_ltm'].replace(0, .01)\n",
    "    df['number_of_reviews_l30d'] = df['number_of_reviews_l30d'].replace(0, .01)\n",
    "    df['host_total_listings_count'] = df['host_total_listings_count'].replace(0, .01)\n",
    "    df['host_listings_count'] = df['host_listings_count'].replace(0, .01)\n",
    "    df['calculated_host_listings_count_private_rooms'] = df['calculated_host_listings_count_private_rooms'].replace(0, .01)\n",
    "    df['calculated_host_listings_count_shared_rooms'] = df['calculated_host_listings_count_shared_rooms'].replace(0, .01)\n",
    "    df['calculated_host_listings_count_entire_homes'] = df['calculated_host_listings_count_entire_homes'].replace(0, .01)\n",
    "    \n",
    "    df['log_beds'] = np.log(df.beds)\n",
    "    df['log_accommodates'] = np.log(df.accommodates)\n",
    "    df['log_reviews'] = np.log(df.number_of_reviews)\n",
    "    df['log_reviews_per_month'] = np.log(df.reviews_per_month)\n",
    "    df['log_reviews_ltm'] = np.log(df.number_of_reviews_ltm)\n",
    "    df['log_reviews_l30d'] = np.log(df.number_of_reviews_l30d)\n",
    "    df['log_host_total_listings_count'] = np.log(df.host_total_listings_count)\n",
    "    df['log_host_listings_count'] = np.log(df.host_listings_count)\n",
    "    df['log_host_listings_count_private_rooms'] = np.log(df.calculated_host_listings_count_private_rooms)\n",
    "    df['log_host_listings_count_shared_rooms'] = np.log(df.calculated_host_listings_count_shared_rooms)\n",
    "    df['log_host_listings_count_entire_homes'] = np.log(df.calculated_host_listings_count_entire_homes)\n",
    "\n",
    "    # calculate the number of days since the host became a host\n",
    "    df['host_since'] = pd.to_datetime(df['host_since'])\n",
    "    current_date = dt.now()\n",
    "    df['host_since_days'] = (current_date - df['host_since']).dt.days\n",
    "    \n",
    "    # calculate days since first/last review\n",
    "    df['first_review'] = pd.to_datetime(df['first_review'], errors='coerce')\n",
    "    df['last_review'] = pd.to_datetime(df['last_review'], errors='coerce')\n",
    "\n",
    "    df['first_review_days'] = (current_date - df['first_review']).dt.days\n",
    "    df['last_review_days'] = (current_date - df['last_review']).dt.days\n",
    "    \n",
    "    # make response_rate and acceptance_rate into numeric dtype\n",
    "    df['host_response_rate'] = df['host_response_rate'].str.rstrip('%').astype('float')\n",
    "    df['host_acceptance_rate'] = df['host_acceptance_rate'].str.rstrip('%').astype('float')\n",
    "    \n",
    "    # subgroup property_type (similar levels as room_type so discard room predictor)\n",
    "    df['property_cats'] = df['property_type'].apply(categorize_property)\n",
    "    \n",
    "    # extract numeric values from the 'bathrooms' column\n",
    "    df['bath_numeric'] = df['bathrooms_text'].str.extract('(\\d+\\.*\\d*)', expand=False).astype(float)\n",
    "\n",
    "    # handle \"Half-bath\" by assigning a numeric value of 0.5\n",
    "    df['bath_numeric'] = df.apply(lambda row: 0.5 if 'half' in row['bathrooms_text'].lower() \\\n",
    "                                  else row['bath_numeric'], axis=1)\n",
    "    \n",
    "    # to binary\n",
    "    df.host_identity_verified = df.host_identity_verified.replace({'t': 1, 'f': 0})\n",
    "    df.host_has_profile_pic = df.host_has_profile_pic.replace({'t': 1, 'f': 0})\n",
    "    df.has_availability = df.has_availability.replace({'t': 1, 'f': 0})\n",
    "    df.instant_bookable = df.instant_bookable.replace({'t': 1, 'f': 0})\n",
    "\n",
    "    # drop the modified/redundant columns\n",
    "    df.drop(columns = ['host_since', 'first_review', 'last_review', 'property_type', 'bathrooms_text', \\\n",
    "                       'number_of_reviews', 'reviews_per_month', 'number_of_reviews_ltm', \\\n",
    "                       'number_of_reviews_l30d', 'host_total_listings_count', 'host_listings_count', \\\n",
    "                      'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms', \\\n",
    "                       'calculated_host_listings_count_entire_homes'], inplace = True)\n",
    "    \n",
    "    # drop predictors that have low corr with log_price and high corr with others to help remove multi-collinearity\n",
    "    df.drop(columns = ['first_review_days', 'last_review_days', 'host_acceptance_rate', 'host_response_rate', \n",
    "                       'availability_60', 'availability_90', 'minimum_minimum_nights', \\\n",
    "                       'maximum_maximum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', \\\n",
    "                       'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "549b8e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data(train)\n",
    "clean_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "c9f480fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the string categorical predictors \n",
    "train = train.drop(columns = ['host_neighbourhood', 'neighbourhood_cleansed', 'host_location'])\n",
    "test = test.drop(columns = ['host_neighbourhood', 'neighbourhood_cleansed', 'host_location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "f5ecbf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE the remaining categorical variables\n",
    "host_response_time_dummies = pd.get_dummies(train['host_response_time'], prefix='host_response_time')\n",
    "train = pd.concat([train, host_response_time_dummies], axis = 1)\n",
    "\n",
    "host_response_time_dummies = pd.get_dummies(test['host_response_time'], prefix='host_response_time')\n",
    "test = pd.concat([test, host_response_time_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "516a783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_verifications_dummies = pd.get_dummies(train['host_verifications'], prefix='host_verifications')\n",
    "train = pd.concat([train, host_verifications_dummies], axis = 1)\n",
    "\n",
    "host_verifications_dummies = pd.get_dummies(test['host_verifications'], prefix='host_verifications')\n",
    "test = pd.concat([test, host_verifications_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "fd780cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "room_type_dummies = pd.get_dummies(train['room_type'], prefix='room_type')\n",
    "train = pd.concat([train, room_type_dummies], axis = 1)\n",
    "\n",
    "room_type_dummies = pd.get_dummies(test['room_type'], prefix='room_type')\n",
    "test = pd.concat([test, room_type_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c5f168f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_cats_dummies = pd.get_dummies(train['property_cats'], prefix='property_cats')\n",
    "train = pd.concat([train, property_cats_dummies], axis = 1)\n",
    "\n",
    "property_cats_dummies = pd.get_dummies(test['property_cats'], prefix='property_cats')\n",
    "test = pd.concat([test, property_cats_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "3e959c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns = ['host_response_time', 'host_verifications', 'room_type', 'property_cats'])\n",
    "test = test.drop(columns = ['host_response_time', 'host_verifications', 'room_type', 'property_cats'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "3f850ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable spacing\n",
    "train.rename(columns=lambda x: x.replace(' ', '_'), inplace=True)\n",
    "test.rename(columns=lambda x: x.replace(' ', '_'), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4570a5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set response and predictors for scaling\n",
    "y_train = train.host_is_superhost\n",
    "X_train = train.drop(columns = ['id', 'host_is_superhost', 'host_id'])\n",
    "X_test = test.drop(columns = ['id', 'host_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e933972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poly features\n",
    "poly = PolynomialFeatures(degree = 2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "d8441363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the variables\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_poly)\n",
    "X_test_scaled = scaler.transform(X_test_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730eaefd",
   "metadata": {},
   "source": [
    "## 2) Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9b39b7",
   "metadata": {},
   "source": [
    "### How many attempts did it take you to tune the model hyperparameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e33d51",
   "metadata": {},
   "source": [
    "It took me around 5 attempts to tune the model hyperparamters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6f50fd",
   "metadata": {},
   "source": [
    "### Which tuning method did you use (grid search / Bayes search / etc.)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ea3666",
   "metadata": {},
   "source": [
    "I used Randomized Search to tune my model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0da667",
   "metadata": {},
   "source": [
    "### What challenges did you face while tuning the hyperparameters, and what actions did you take to address those challenges?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe8149e",
   "metadata": {},
   "source": [
    "The main challenge I faced was trying to figure out the right amount of Polynomial Features to use, and I came to the conclusion that any above 2 was unnecessary and too complex. I also had to choose a variable selection method first before running KNN, as unncessary predictors would negatively incluence KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f26daac",
   "metadata": {},
   "source": [
    "### How many hours did you spend on hyperparameter tuning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8149d3",
   "metadata": {},
   "source": [
    "Each run of the hyperparamter tuning took around a few minutes. In total, it took me around 1 hour on hyperparameter tuning in addition to the time it took to implement Lasso. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591e4d91",
   "metadata": {},
   "source": [
    "### Variable Selection Step: Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba4abb9",
   "metadata": {},
   "source": [
    "**Paste the hyperparameter tuning code below. You must show at least one hyperparameter tuning procedure.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efccf837",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "64a4f964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create DataFrames with polynomial features\n",
    "X_train_poly_df = pd.DataFrame(X_train_scaled, columns=poly.get_feature_names_out(X_train.columns))\n",
    "X_test_poly_df = pd.DataFrame(X_test_scaled, columns=poly.get_feature_names_out(X_test.columns))\n",
    "\n",
    "selected_coeffs = []\n",
    "r = 0\n",
    "alphas = np.logspace(-1, 3, 200)\n",
    "kfold = KFold(n_splits = 10, shuffle = True, random_state = 1)\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha = alpha)\n",
    "    lasso.fit(X_train_scaled,y_train)\n",
    "    if ((lasso.coef_ == 0).sum() > r) & (len(selected_coeffs) <= r) :\n",
    "        selected_coeffs.append(np.where(lasso.coef_!=0)[0])\n",
    "        r = r + 1\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "grid = {'n_neighbors': np.arange(1, 61, 2), 'weights': ['uniform', 'distance'], 'metric': ['manhattan', 'euclidean', 'minkowski'], \\\n",
    "        'p': np.arange(1, 5)}\n",
    "\n",
    "results = []\n",
    "for r in range(1, 51):\n",
    "    \n",
    "    gcv = RandomizedSearchCV(model, grid, cv = kfold, n_iter = 300, random_state = 10,\n",
    "                         scoring = 'neg_root_mean_squared_error', n_jobs = -1)\n",
    "    selected_Xs = X_train_poly_df.iloc[:,selected_coeffs[r-1]]\n",
    "    selected_predictors = selected_Xs.columns.tolist()\n",
    "    \n",
    "    if selected_Xs.shape[1] > 0:\n",
    "        gcv.fit(selected_Xs, y_train)\n",
    "    \n",
    "        cv_rmse = np.sqrt(-gcv.best_score_)\n",
    "    \n",
    "        results.append({'r': r,\n",
    "                    'selected_predictors': selected_predictors,\n",
    "                    'best_params': gcv.best_params_,\n",
    "                    'cv_rmse': cv_rmse})\n",
    "        \n",
    "optimal_r = min(results, key = lambda x: x['cv_rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f934f84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract selected predictors column names\n",
    "selected_predictors = optimal_r['selected_predictors'][0].split()  # Convert the string to a list of column names\n",
    "\n",
    "# Find indices of selected predictor column names\n",
    "selected_predictor_indices = [X_train_poly_df.columns.get_loc(col) for col in selected_predictors]\n",
    "\n",
    "# Extract selected predictor column names\n",
    "selected_predictor_names = X_train_poly_df.columns[selected_predictor_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc357d",
   "metadata": {},
   "source": [
    "**Paste the optimal hyperparameter values below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "de128a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': 'uniform', 'p': 3, 'n_neighbors': 39, 'metric': 'euclidean'}\n"
     ]
    }
   ],
   "source": [
    "print(optimal_r['best_params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e104de7",
   "metadata": {},
   "source": [
    "## 3) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a37864",
   "metadata": {},
   "source": [
    "Using the optimal model hyperparameters, train the model, and paste the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "a6462944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_neighbors=39, p=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_neighbors=39, p=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(metric='euclidean', n_neighbors=39, p=3)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit the model\n",
    "model = KNeighborsClassifier(**optimal_r['best_params'])\n",
    "model.fit(X_train_poly_df[selected_predictor_names], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897d6954",
   "metadata": {},
   "source": [
    "## 4) Put any ad-hoc steps for further improving model accuracy\n",
    "For example, scaling up or scaling down the predictions, capping predictions, etc.\n",
    "\n",
    "Put code below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2efef5",
   "metadata": {},
   "source": [
    "#### Implementing `host id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "50f83882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "pred = model.predict(X_test_poly_df[selected_predictor_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "a23aa474",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = test.id.values\n",
    "predicted = pred\n",
    "submission = pd.DataFrame({'id': id, 'predicted': predicted})\n",
    "submission = submission.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d07599c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'host_id' to submission\n",
    "submission['host_id'] = test['host_id']\n",
    "\n",
    "# Use apply to replace 'predicted' based on 'host_id'\n",
    "submission['predicted'] = submission.apply(lambda row: train[train['host_id'] == row['host_id']]['host_is_superhost'].values[0] \n",
    "                                           if not train[train['host_id'] == row['host_id']].empty else row['predicted'], axis=1)\n",
    "\n",
    "# Drop 'host_id' from submission\n",
    "submission = submission.drop(columns=['host_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1c5d42",
   "metadata": {},
   "source": [
    "## 5) Export the predictions in the format required to submit on Kaggle\n",
    "Put code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "465a1681",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('classification_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
