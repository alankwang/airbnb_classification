{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b1c13c80",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Prediction Problem Report (Name of model (KNN / RF / Boosting / Ensemble); Regression / Classification)\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "    html-math-method: mathml \n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4b9670",
   "metadata": {},
   "source": [
    "## Instructions {-}\n",
    "\n",
    "- This is the template for the code and report on the Prediction Problem assignments.\n",
    "\n",
    "- Your code in steps 1, 3, 4, and 5 will be executed sequentially, and must produce the RMSE / accuracy claimed on Kaggle.\n",
    "\n",
    "- Your code in step 2 will also be executed, and must produce the optimal hyperparameter values used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "238ab792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score,train_test_split, KFold, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error,r2_score,roc_curve,auc,precision_recall_curve, accuracy_score, \\\n",
    "recall_score, precision_score, confusion_matrix, mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import BaggingRegressor,BaggingClassifier,AdaBoostRegressor,AdaBoostClassifier, \\\n",
    "RandomForestRegressor, GradientBoostingRegressor,VotingRegressor, StackingRegressor, VotingClassifier, StackingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, Ridge, Lasso,LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import itertools as it\n",
    "import time as time\n",
    "import xgboost as xgb\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_objective, plot_histogram, plot_convergence\n",
    "import warnings\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e86f05",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06025554",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./datasets/train_classification.csv')\n",
    "test = pd.read_csv('./datasets/test_classification.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5d4b16",
   "metadata": {},
   "source": [
    "## 1) Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adc06dc",
   "metadata": {},
   "source": [
    "Put the data pre-processing code. You don't need to explain it. You may use the same code from last quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2984ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['has_missing'] = train.isnull().any(axis=1).astype(int)\n",
    "test['has_missing'] = test.isnull().any(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47a61e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to categorize the property types\n",
    "def categorize_property(property_type):\n",
    "    if 'Entire' in property_type:\n",
    "        return 'Entire Home/Apartment'\n",
    "    elif 'Private' in property_type:\n",
    "        return 'Private Room'\n",
    "    elif 'Shared' in property_type:\n",
    "        return 'Shared Accommodation'\n",
    "    elif property_type in ['Room in hotel', 'Room in boutique hotel', 'Boat']:\n",
    "        return 'Specialty Accommodations'\n",
    "    else:\n",
    "        return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a12b2717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall function to clean training and test data\n",
    "def clean_data(df):\n",
    "    \n",
    "    if 'host_is_superhost' in df.columns:\n",
    "        df.host_is_superhost = df.host_is_superhost.replace({'t': 1, 'f': 0})\n",
    "        \n",
    "    # replace missing values of numeric variables wtih the median\n",
    "    numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "    df[numeric_columns] = df[numeric_columns].apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "    # replace missing values of categorical variables with the mode \n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    df[categorical_columns] = df[categorical_columns].fillna(df[categorical_columns].mode().iloc[0])\n",
    "    \n",
    "    # replace any 0 values to 1 so that it can go through log transformation\n",
    "    df['beds'] = df['beds'].replace(0, .01)\n",
    "    df['accommodates'] = df['accommodates'].replace(0, .01)\n",
    "    df['number_of_reviews'] = df['number_of_reviews'].replace(0, .01)\n",
    "    df['reviews_per_month'] = df['reviews_per_month'].replace(0, .01)\n",
    "    df['number_of_reviews_ltm'] = df['number_of_reviews_ltm'].replace(0, .01)\n",
    "    df['number_of_reviews_l30d'] = df['number_of_reviews_l30d'].replace(0, .01)\n",
    "    df['host_total_listings_count'] = df['host_total_listings_count'].replace(0, .01)\n",
    "    df['host_listings_count'] = df['host_listings_count'].replace(0, .01)\n",
    "    df['calculated_host_listings_count_private_rooms'] = df['calculated_host_listings_count_private_rooms'].replace(0, .01)\n",
    "    df['calculated_host_listings_count_shared_rooms'] = df['calculated_host_listings_count_shared_rooms'].replace(0, .01)\n",
    "    df['calculated_host_listings_count_entire_homes'] = df['calculated_host_listings_count_entire_homes'].replace(0, .01)\n",
    "    \n",
    "    df['log_beds'] = np.log(df.beds)\n",
    "    df['log_accommodates'] = np.log(df.accommodates)\n",
    "    df['log_reviews'] = np.log(df.number_of_reviews)\n",
    "    df['log_reviews_per_month'] = np.log(df.reviews_per_month)\n",
    "    df['log_reviews_ltm'] = np.log(df.number_of_reviews_ltm)\n",
    "    df['log_reviews_l30d'] = np.log(df.number_of_reviews_l30d)\n",
    "    df['log_host_total_listings_count'] = np.log(df.host_total_listings_count)\n",
    "    df['log_host_listings_count'] = np.log(df.host_listings_count)\n",
    "    df['log_host_listings_count_private_rooms'] = np.log(df.calculated_host_listings_count_private_rooms)\n",
    "    df['log_host_listings_count_shared_rooms'] = np.log(df.calculated_host_listings_count_shared_rooms)\n",
    "    df['log_host_listings_count_entire_homes'] = np.log(df.calculated_host_listings_count_entire_homes)\n",
    "\n",
    "    # calculate the number of days since the host became a host\n",
    "    df['host_since'] = pd.to_datetime(df['host_since'])\n",
    "    current_date = dt.now()\n",
    "    df['host_since_days'] = (current_date - df['host_since']).dt.days\n",
    "    \n",
    "    # calculate days since first/last review\n",
    "    df['first_review'] = pd.to_datetime(df['first_review'], errors='coerce')\n",
    "    df['last_review'] = pd.to_datetime(df['last_review'], errors='coerce')\n",
    "\n",
    "    df['first_review_days'] = (current_date - df['first_review']).dt.days\n",
    "    df['last_review_days'] = (current_date - df['last_review']).dt.days\n",
    "    \n",
    "    # make response_rate and acceptance_rate into numeric dtype\n",
    "    df['host_response_rate'] = df['host_response_rate'].str.rstrip('%').astype('float')\n",
    "    df['host_acceptance_rate'] = df['host_acceptance_rate'].str.rstrip('%').astype('float')\n",
    "    \n",
    "    # subgroup property_type (similar levels as room_type so discard room predictor)\n",
    "    df['property_cats'] = df['property_type'].apply(categorize_property)\n",
    "    \n",
    "    # extract numeric values from the 'bathrooms' column\n",
    "    df['bath_numeric'] = df['bathrooms_text'].str.extract('(\\d+\\.*\\d*)', expand=False).astype(float)\n",
    "\n",
    "    # handle \"Half-bath\" by assigning a numeric value of 0.5\n",
    "    df['bath_numeric'] = df.apply(lambda row: 0.5 if 'half' in row['bathrooms_text'].lower() \\\n",
    "                                  else row['bath_numeric'], axis=1)\n",
    "    \n",
    "    # to binary\n",
    "    df.host_identity_verified = df.host_identity_verified.replace({'t': 1, 'f': 0})\n",
    "    df.host_has_profile_pic = df.host_has_profile_pic.replace({'t': 1, 'f': 0})\n",
    "    df.has_availability = df.has_availability.replace({'t': 1, 'f': 0})\n",
    "    df.instant_bookable = df.instant_bookable.replace({'t': 1, 'f': 0})\n",
    "\n",
    "    # drop the modified/redundant columns\n",
    "    df.drop(columns = ['host_since', 'first_review', 'last_review', 'property_type', 'bathrooms_text', \\\n",
    "                       'number_of_reviews', 'reviews_per_month', 'number_of_reviews_ltm', \\\n",
    "                       'number_of_reviews_l30d', 'host_total_listings_count', 'host_listings_count', \\\n",
    "                      'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms', \\\n",
    "                       'calculated_host_listings_count_entire_homes'], inplace = True)\n",
    "    \n",
    "    # drop predictors that have low corr with log_price and high corr with others to help remove multi-collinearity\n",
    "    df.drop(columns = ['first_review_days', 'last_review_days', 'host_acceptance_rate', 'host_response_rate', \n",
    "                       'availability_60', 'availability_90', 'minimum_minimum_nights', \\\n",
    "                       'maximum_maximum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', \\\n",
    "                       'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c47ea132",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data(train)\n",
    "clean_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dc151f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the string categorical predictors \n",
    "train = train.drop(columns = ['host_neighbourhood', 'neighbourhood_cleansed', 'host_location'])\n",
    "test = test.drop(columns = ['host_neighbourhood', 'neighbourhood_cleansed', 'host_location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1568fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE the remaining categorical variables\n",
    "host_response_time_dummies = pd.get_dummies(train['host_response_time'], prefix='host_response_time')\n",
    "train = pd.concat([train, host_response_time_dummies], axis = 1)\n",
    "\n",
    "host_response_time_dummies = pd.get_dummies(test['host_response_time'], prefix='host_response_time')\n",
    "test = pd.concat([test, host_response_time_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13ad0214",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_verifications_dummies = pd.get_dummies(train['host_verifications'], prefix='host_verifications')\n",
    "train = pd.concat([train, host_verifications_dummies], axis = 1)\n",
    "\n",
    "host_verifications_dummies = pd.get_dummies(test['host_verifications'], prefix='host_verifications')\n",
    "test = pd.concat([test, host_verifications_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e912301",
   "metadata": {},
   "outputs": [],
   "source": [
    "room_type_dummies = pd.get_dummies(train['room_type'], prefix='room_type')\n",
    "train = pd.concat([train, room_type_dummies], axis = 1)\n",
    "\n",
    "room_type_dummies = pd.get_dummies(test['room_type'], prefix='room_type')\n",
    "test = pd.concat([test, room_type_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2db726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_cats_dummies = pd.get_dummies(train['property_cats'], prefix='property_cats')\n",
    "train = pd.concat([train, property_cats_dummies], axis = 1)\n",
    "\n",
    "property_cats_dummies = pd.get_dummies(test['property_cats'], prefix='property_cats')\n",
    "test = pd.concat([test, property_cats_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55f498b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns = ['host_response_time', 'host_verifications', 'room_type', 'property_cats'])\n",
    "test = test.drop(columns = ['host_response_time', 'host_verifications', 'room_type', 'property_cats'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc346dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable spacing\n",
    "train.rename(columns=lambda x: x.replace(' ', '_'), inplace=True)\n",
    "test.rename(columns=lambda x: x.replace(' ', '_'), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dd25ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set response and predictors for scaling\n",
    "y_train = train.host_is_superhost\n",
    "X_train = train.drop(columns = ['id', 'host_is_superhost', 'host_id'])\n",
    "X_test = test.drop(columns = ['id', 'host_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fcf7798",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_scaled = sc.transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87f77997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LassoCV(alphas=array([1.00000000e-04, 1.12332403e-04, 1.26185688e-04, 1.41747416e-04,\n",
       "       1.59228279e-04, 1.78864953e-04, 2.00923300e-04, 2.25701972e-04,\n",
       "       2.53536449e-04, 2.84803587e-04, 3.19926714e-04, 3.59381366e-04,\n",
       "       4.03701726e-04, 4.53487851e-04, 5.09413801e-04, 5.72236766e-04,\n",
       "       6.42807312e-04, 7.22080902e-04, 8.11130831e-04, 9.11162756e-04,\n",
       "       1.02353102e-03, 1.14975700e-0...\n",
       "       6.89261210e-01, 7.74263683e-01, 8.69749003e-01, 9.77009957e-01,\n",
       "       1.09749877e+00, 1.23284674e+00, 1.38488637e+00, 1.55567614e+00,\n",
       "       1.74752840e+00, 1.96304065e+00, 2.20513074e+00, 2.47707636e+00,\n",
       "       2.78255940e+00, 3.12571585e+00, 3.51119173e+00, 3.94420606e+00,\n",
       "       4.43062146e+00, 4.97702356e+00, 5.59081018e+00, 6.28029144e+00,\n",
       "       7.05480231e+00, 7.92482898e+00, 8.90215085e+00, 1.00000000e+01]),\n",
       "        cv=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LassoCV</label><div class=\"sk-toggleable__content\"><pre>LassoCV(alphas=array([1.00000000e-04, 1.12332403e-04, 1.26185688e-04, 1.41747416e-04,\n",
       "       1.59228279e-04, 1.78864953e-04, 2.00923300e-04, 2.25701972e-04,\n",
       "       2.53536449e-04, 2.84803587e-04, 3.19926714e-04, 3.59381366e-04,\n",
       "       4.03701726e-04, 4.53487851e-04, 5.09413801e-04, 5.72236766e-04,\n",
       "       6.42807312e-04, 7.22080902e-04, 8.11130831e-04, 9.11162756e-04,\n",
       "       1.02353102e-03, 1.14975700e-0...\n",
       "       6.89261210e-01, 7.74263683e-01, 8.69749003e-01, 9.77009957e-01,\n",
       "       1.09749877e+00, 1.23284674e+00, 1.38488637e+00, 1.55567614e+00,\n",
       "       1.74752840e+00, 1.96304065e+00, 2.20513074e+00, 2.47707636e+00,\n",
       "       2.78255940e+00, 3.12571585e+00, 3.51119173e+00, 3.94420606e+00,\n",
       "       4.43062146e+00, 4.97702356e+00, 5.59081018e+00, 6.28029144e+00,\n",
       "       7.05480231e+00, 7.92482898e+00, 8.90215085e+00, 1.00000000e+01]),\n",
       "        cv=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LassoCV(alphas=array([1.00000000e-04, 1.12332403e-04, 1.26185688e-04, 1.41747416e-04,\n",
       "       1.59228279e-04, 1.78864953e-04, 2.00923300e-04, 2.25701972e-04,\n",
       "       2.53536449e-04, 2.84803587e-04, 3.19926714e-04, 3.59381366e-04,\n",
       "       4.03701726e-04, 4.53487851e-04, 5.09413801e-04, 5.72236766e-04,\n",
       "       6.42807312e-04, 7.22080902e-04, 8.11130831e-04, 9.11162756e-04,\n",
       "       1.02353102e-03, 1.14975700e-0...\n",
       "       6.89261210e-01, 7.74263683e-01, 8.69749003e-01, 9.77009957e-01,\n",
       "       1.09749877e+00, 1.23284674e+00, 1.38488637e+00, 1.55567614e+00,\n",
       "       1.74752840e+00, 1.96304065e+00, 2.20513074e+00, 2.47707636e+00,\n",
       "       2.78255940e+00, 3.12571585e+00, 3.51119173e+00, 3.94420606e+00,\n",
       "       4.43062146e+00, 4.97702356e+00, 5.59081018e+00, 6.28029144e+00,\n",
       "       7.05480231e+00, 7.92482898e+00, 8.90215085e+00, 1.00000000e+01]),\n",
       "        cv=10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = np.logspace(-4,1,100)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "lcv = LassoCV(alphas=alphas, cv=10)\n",
    "lcv.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "607110b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cleaned = X_train_scaled.T[lcv.coef_!=0].T\n",
    "X_test_cleaned = X_test_scaled.T[lcv.coef_!=0].T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730eaefd",
   "metadata": {},
   "source": [
    "## 2) Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9b39b7",
   "metadata": {},
   "source": [
    "### How many attempts did it take you to tune the model hyperparameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e33d51",
   "metadata": {},
   "source": [
    "I took me around 20+ attempts to tune the model hyperparamters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6f50fd",
   "metadata": {},
   "source": [
    "### Which tuning method did you use (grid search / Bayes search / etc.)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ea3666",
   "metadata": {},
   "source": [
    "I used Grid Search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0da667",
   "metadata": {},
   "source": [
    "### What challenges did you face while tuning the hyperparameters, and what actions did you take to address those challenges?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe8149e",
   "metadata": {},
   "source": [
    "There were not that many challenges tuning the hyperparamters, the main challenge was making sure that the dataset was properly prepared for the models. Narrowing down the ranges was easier this time as I just used the same tuning methods as the previous models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f26daac",
   "metadata": {},
   "source": [
    "### How many hours did you spend on hyperparameter tuning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8149d3",
   "metadata": {},
   "source": [
    "It took me around 6 hours to tune."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba4abb9",
   "metadata": {},
   "source": [
    "**Paste the hyperparameter tuning code below. You must show at least one hyperparameter tuning procedure.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efccf837",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fdc0e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = DecisionTreeClassifier(random_state = 1, max_depth=16, max_leaf_nodes=186)\n",
    "ada = AdaBoostClassifier(estimator = base_model, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3901dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle = True, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "03e67554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "0.8854694431650142\n",
      "{'estimator__max_depth': 11, 'learning_rate': 1, 'n_estimators': 190}\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ada_grid = {'estimator__max_depth': [11, 12],\n",
    "        'n_estimators': [190],\n",
    "        'learning_rate': [1,10]\n",
    "       } \n",
    "\n",
    "ada_gcv = GridSearchCV(ada, ada_grid, cv = skf, scoring = 'accuracy', n_jobs = -1, verbose = 1)\n",
    "\n",
    "ada_gcv.fit(X_train_cleaned, y_train)\n",
    "\n",
    "print(ada_gcv.best_score_)\n",
    "print(ada_gcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe151b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(random_state=1, n_estimators=200, bootstrap=True, max_features=0.75, \n",
    "                                 max_samples=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8150ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = DecisionTreeClassifier(random_state=1) \n",
    "bag_model = BaggingClassifier(estimator=base_model, bootstrap=False, bootstrap_features=False, max_features=0.75,\n",
    "                             max_samples=0.9, n_estimators=250, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "01c6bda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model1 = DecisionTreeClassifier(random_state = 1, max_depth = 11)\n",
    "ada_model = AdaBoostClassifier(estimator = base_model1, random_state = 1, learning_rate = 1, n_estimators = 190)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc357d",
   "metadata": {},
   "source": [
    "**Paste the optimal hyperparameter values below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67efc616",
   "metadata": {},
   "source": [
    "The optimal hyperparamter values are inputted above, I am using the hyperparamters that obtained the best scores I achieved from before with each model, though I improved upon the AdaBoost model a bit further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e104de7",
   "metadata": {},
   "source": [
    "## 3) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a37864",
   "metadata": {},
   "source": [
    "Using the optimal model hyperparameters, train the model, and paste the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4948a195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(cv=StratifiedKFold(n_splits=5, random_state=1, shuffle=True),\n",
       "                   estimators=[(&#x27;bag&#x27;,\n",
       "                                BaggingClassifier(bootstrap=False,\n",
       "                                                  estimator=DecisionTreeClassifier(random_state=1),\n",
       "                                                  max_features=0.75,\n",
       "                                                  max_samples=0.9,\n",
       "                                                  n_estimators=250,\n",
       "                                                  random_state=1)),\n",
       "                               (&#x27;ada&#x27;,\n",
       "                                AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=11,\n",
       "                                                                                    random_state=1),\n",
       "                                                   learning_rate=1,\n",
       "                                                   n_estimators=190,\n",
       "                                                   random_state=1))],\n",
       "                   final_estimator=LogisticRegression(max_iter=10000,\n",
       "                                                      random_state=1),\n",
       "                   n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-59\" type=\"checkbox\" ><label for=\"sk-estimator-id-59\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(cv=StratifiedKFold(n_splits=5, random_state=1, shuffle=True),\n",
       "                   estimators=[(&#x27;bag&#x27;,\n",
       "                                BaggingClassifier(bootstrap=False,\n",
       "                                                  estimator=DecisionTreeClassifier(random_state=1),\n",
       "                                                  max_features=0.75,\n",
       "                                                  max_samples=0.9,\n",
       "                                                  n_estimators=250,\n",
       "                                                  random_state=1)),\n",
       "                               (&#x27;ada&#x27;,\n",
       "                                AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=11,\n",
       "                                                                                    random_state=1),\n",
       "                                                   learning_rate=1,\n",
       "                                                   n_estimators=190,\n",
       "                                                   random_state=1))],\n",
       "                   final_estimator=LogisticRegression(max_iter=10000,\n",
       "                                                      random_state=1),\n",
       "                   n_jobs=-1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>bag</label></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-60\" type=\"checkbox\" ><label for=\"sk-estimator-id-60\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-61\" type=\"checkbox\" ><label for=\"sk-estimator-id-61\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=1)</pre></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>ada</label></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-62\" type=\"checkbox\" ><label for=\"sk-estimator-id-62\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=11, random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-63\" type=\"checkbox\" ><label for=\"sk-estimator-id-63\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=11, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-64\" type=\"checkbox\" ><label for=\"sk-estimator-id-64\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(cv=StratifiedKFold(n_splits=5, random_state=1, shuffle=True),\n",
       "                   estimators=[('bag',\n",
       "                                BaggingClassifier(bootstrap=False,\n",
       "                                                  estimator=DecisionTreeClassifier(random_state=1),\n",
       "                                                  max_features=0.75,\n",
       "                                                  max_samples=0.9,\n",
       "                                                  n_estimators=250,\n",
       "                                                  random_state=1)),\n",
       "                               ('ada',\n",
       "                                AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=11,\n",
       "                                                                                    random_state=1),\n",
       "                                                   learning_rate=1,\n",
       "                                                   n_estimators=190,\n",
       "                                                   random_state=1))],\n",
       "                   final_estimator=LogisticRegression(max_iter=10000,\n",
       "                                                      random_state=1),\n",
       "                   n_jobs=-1)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en = StackingClassifier(estimators=[('bag',bag_model),('ada',ada_model)],\n",
    "                                   final_estimator=LogisticRegression(random_state=1,max_iter=10000),n_jobs=-1,\n",
    "                                   cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=1))\n",
    "en.fit(X_train_cleaned, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e288aa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = en.predict(X_test_cleaned)\n",
    "y_preds = y_preds.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897d6954",
   "metadata": {},
   "source": [
    "## 4) Put any ad-hoc steps for further improving model accuracy\n",
    "For example, scaling up or scaling down the predictions, capping predictions, etc.\n",
    "\n",
    "Put code below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376a0ce8",
   "metadata": {},
   "source": [
    "#### Implementing `host_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "786487cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = test.id.values\n",
    "predicted = y_preds\n",
    "submission = pd.DataFrame({'id': id, 'predicted': predicted})\n",
    "submission = submission.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "32bc5286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'host_id' to submission\n",
    "submission['host_id'] = test['host_id']\n",
    "\n",
    "# Use apply to replace 'predicted' based on 'host_id'\n",
    "submission['predicted'] = submission.apply(lambda row: train[train['host_id'] == row['host_id']]['host_is_superhost'].values[0] \n",
    "                                           if not train[train['host_id'] == row['host_id']].empty else row['predicted'], axis=1)\n",
    "\n",
    "# Drop 'host_id' from submission\n",
    "submission = submission.drop(columns=['host_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1c5d42",
   "metadata": {},
   "source": [
    "## 5) Export the predictions in the format required to submit on Kaggle\n",
    "Put code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "31202106",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('ensemble_classification_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
