{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b1c13c80",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Prediction Problem Report (Boosting ; Classification)\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "    html-math-method: mathml \n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "14d6ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score,train_test_split, KFold, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error,r2_score,roc_curve,auc,precision_recall_curve, accuracy_score, \\\n",
    "recall_score, precision_score, confusion_matrix, mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import BaggingRegressor,BaggingClassifier,AdaBoostRegressor,AdaBoostClassifier, \\\n",
    "RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import itertools as it\n",
    "import time as time\n",
    "import xgboost as xgb\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_objective, plot_histogram, plot_convergence\n",
    "import warnings\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e86f05",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06025554",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./datasets/train_classification.csv')\n",
    "test = pd.read_csv('./datasets/test_classification.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5d4b16",
   "metadata": {},
   "source": [
    "## 1) Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adc06dc",
   "metadata": {},
   "source": [
    "Put the data pre-processing code. You don't need to explain it. You may use the same code from last quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b1da437",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['has_missing'] = train.isnull().any(axis=1).astype(int)\n",
    "test['has_missing'] = test.isnull().any(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f57fbec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to categorize the property types\n",
    "def categorize_property(property_type):\n",
    "    if 'Entire' in property_type:\n",
    "        return 'Entire Home/Apartment'\n",
    "    elif 'Private' in property_type:\n",
    "        return 'Private Room'\n",
    "    elif 'Shared' in property_type:\n",
    "        return 'Shared Accommodation'\n",
    "    elif property_type in ['Room in hotel', 'Room in boutique hotel', 'Boat']:\n",
    "        return 'Specialty Accommodations'\n",
    "    else:\n",
    "        return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b170474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall function to clean training and test data\n",
    "def clean_data(df):\n",
    "    \n",
    "    if 'host_is_superhost' in df.columns:\n",
    "        df.host_is_superhost = df.host_is_superhost.replace({'t': 1, 'f': 0})\n",
    "        \n",
    "    # replace missing values of numeric variables wtih the median\n",
    "    numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "    df[numeric_columns] = df[numeric_columns].apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "    # replace missing values of categorical variables with the mode \n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    df[categorical_columns] = df[categorical_columns].fillna(df[categorical_columns].mode().iloc[0])\n",
    "    \n",
    "    # replace any 0 values to 1 so that it can go through log transformation\n",
    "    df['beds'] = df['beds'].replace(0, .01)\n",
    "    df['accommodates'] = df['accommodates'].replace(0, .01)\n",
    "    df['number_of_reviews'] = df['number_of_reviews'].replace(0, .01)\n",
    "    df['reviews_per_month'] = df['reviews_per_month'].replace(0, .01)\n",
    "    df['number_of_reviews_ltm'] = df['number_of_reviews_ltm'].replace(0, .01)\n",
    "    df['number_of_reviews_l30d'] = df['number_of_reviews_l30d'].replace(0, .01)\n",
    "    df['host_total_listings_count'] = df['host_total_listings_count'].replace(0, .01)\n",
    "    df['host_listings_count'] = df['host_listings_count'].replace(0, .01)\n",
    "    df['calculated_host_listings_count_private_rooms'] = df['calculated_host_listings_count_private_rooms'].replace(0, .01)\n",
    "    df['calculated_host_listings_count_shared_rooms'] = df['calculated_host_listings_count_shared_rooms'].replace(0, .01)\n",
    "    df['calculated_host_listings_count_entire_homes'] = df['calculated_host_listings_count_entire_homes'].replace(0, .01)\n",
    "    \n",
    "    df['log_beds'] = np.log(df.beds)\n",
    "    df['log_accommodates'] = np.log(df.accommodates)\n",
    "    df['log_reviews'] = np.log(df.number_of_reviews)\n",
    "    df['log_reviews_per_month'] = np.log(df.reviews_per_month)\n",
    "    df['log_reviews_ltm'] = np.log(df.number_of_reviews_ltm)\n",
    "    df['log_reviews_l30d'] = np.log(df.number_of_reviews_l30d)\n",
    "    df['log_host_total_listings_count'] = np.log(df.host_total_listings_count)\n",
    "    df['log_host_listings_count'] = np.log(df.host_listings_count)\n",
    "    df['log_host_listings_count_private_rooms'] = np.log(df.calculated_host_listings_count_private_rooms)\n",
    "    df['log_host_listings_count_shared_rooms'] = np.log(df.calculated_host_listings_count_shared_rooms)\n",
    "    df['log_host_listings_count_entire_homes'] = np.log(df.calculated_host_listings_count_entire_homes)\n",
    "\n",
    "    # calculate the number of days since the host became a host\n",
    "    df['host_since'] = pd.to_datetime(df['host_since'])\n",
    "    current_date = dt.now()\n",
    "    df['host_since_days'] = (current_date - df['host_since']).dt.days\n",
    "    \n",
    "    # calculate days since first/last review\n",
    "    df['first_review'] = pd.to_datetime(df['first_review'], errors='coerce')\n",
    "    df['last_review'] = pd.to_datetime(df['last_review'], errors='coerce')\n",
    "\n",
    "    df['first_review_days'] = (current_date - df['first_review']).dt.days\n",
    "    df['last_review_days'] = (current_date - df['last_review']).dt.days\n",
    "    \n",
    "    # make response_rate and acceptance_rate into numeric dtype\n",
    "    df['host_response_rate'] = df['host_response_rate'].str.rstrip('%').astype('float')\n",
    "    df['host_acceptance_rate'] = df['host_acceptance_rate'].str.rstrip('%').astype('float')\n",
    "    \n",
    "    # subgroup property_type (similar levels as room_type so discard room predictor)\n",
    "    df['property_cats'] = df['property_type'].apply(categorize_property)\n",
    "    \n",
    "    # extract numeric values from the 'bathrooms' column\n",
    "    df['bath_numeric'] = df['bathrooms_text'].str.extract('(\\d+\\.*\\d*)', expand=False).astype(float)\n",
    "\n",
    "    # handle \"Half-bath\" by assigning a numeric value of 0.5\n",
    "    df['bath_numeric'] = df.apply(lambda row: 0.5 if 'half' in row['bathrooms_text'].lower() \\\n",
    "                                  else row['bath_numeric'], axis=1)\n",
    "    \n",
    "    # to binary\n",
    "    df.host_identity_verified = df.host_identity_verified.replace({'t': 1, 'f': 0})\n",
    "    df.host_has_profile_pic = df.host_has_profile_pic.replace({'t': 1, 'f': 0})\n",
    "    df.has_availability = df.has_availability.replace({'t': 1, 'f': 0})\n",
    "    df.instant_bookable = df.instant_bookable.replace({'t': 1, 'f': 0})\n",
    "\n",
    "    # drop the modified/redundant columns\n",
    "    df.drop(columns = ['host_since', 'first_review', 'last_review', 'property_type', 'bathrooms_text', \\\n",
    "                       'number_of_reviews', 'reviews_per_month', 'number_of_reviews_ltm', \\\n",
    "                       'number_of_reviews_l30d', 'host_total_listings_count', 'host_listings_count', \\\n",
    "                      'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms', \\\n",
    "                       'calculated_host_listings_count_entire_homes'], inplace = True)\n",
    "    \n",
    "    # drop predictors that have low corr with log_price and high corr with others to help remove multi-collinearity\n",
    "    df.drop(columns = ['first_review_days', 'last_review_days', 'host_acceptance_rate', 'host_response_rate', \n",
    "                       'availability_60', 'availability_90', 'minimum_minimum_nights', \\\n",
    "                       'maximum_maximum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', \\\n",
    "                       'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "910045f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data(train)\n",
    "clean_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "382335d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the string categorical predictors \n",
    "train = train.drop(columns = ['host_neighbourhood', 'neighbourhood_cleansed', 'host_location'])\n",
    "test = test.drop(columns = ['host_neighbourhood', 'neighbourhood_cleansed', 'host_location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66079cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE the remaining categorical variables\n",
    "host_response_time_dummies = pd.get_dummies(train['host_response_time'], prefix='host_response_time')\n",
    "train = pd.concat([train, host_response_time_dummies], axis = 1)\n",
    "\n",
    "host_response_time_dummies = pd.get_dummies(test['host_response_time'], prefix='host_response_time')\n",
    "test = pd.concat([test, host_response_time_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad99a22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_verifications_dummies = pd.get_dummies(train['host_verifications'], prefix='host_verifications')\n",
    "train = pd.concat([train, host_verifications_dummies], axis = 1)\n",
    "\n",
    "host_verifications_dummies = pd.get_dummies(test['host_verifications'], prefix='host_verifications')\n",
    "test = pd.concat([test, host_verifications_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd465798",
   "metadata": {},
   "outputs": [],
   "source": [
    "room_type_dummies = pd.get_dummies(train['room_type'], prefix='room_type')\n",
    "train = pd.concat([train, room_type_dummies], axis = 1)\n",
    "\n",
    "room_type_dummies = pd.get_dummies(test['room_type'], prefix='room_type')\n",
    "test = pd.concat([test, room_type_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be810b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_cats_dummies = pd.get_dummies(train['property_cats'], prefix='property_cats')\n",
    "train = pd.concat([train, property_cats_dummies], axis = 1)\n",
    "\n",
    "property_cats_dummies = pd.get_dummies(test['property_cats'], prefix='property_cats')\n",
    "test = pd.concat([test, property_cats_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9403b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns = ['host_response_time', 'host_verifications', 'room_type', 'property_cats'])\n",
    "test = test.drop(columns = ['host_response_time', 'host_verifications', 'room_type', 'property_cats'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "648bfb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable spacing\n",
    "train.rename(columns=lambda x: x.replace(' ', '_'), inplace=True)\n",
    "test.rename(columns=lambda x: x.replace(' ', '_'), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3e5c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set response and predictors for scaling\n",
    "y_train = train.host_is_superhost\n",
    "X_train = train.drop(columns = ['id', 'host_is_superhost', 'host_id'])\n",
    "X_test = test.drop(columns = ['id', 'host_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730eaefd",
   "metadata": {},
   "source": [
    "## 2) Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9b39b7",
   "metadata": {},
   "source": [
    "### How many attempts did it take you to tune the model hyperparameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e33d51",
   "metadata": {},
   "source": [
    "It took me around 50 attempts to tune the model hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6f50fd",
   "metadata": {},
   "source": [
    "### Which tuning method did you use (grid search / Bayes search / etc.)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ea3666",
   "metadata": {},
   "source": [
    "I used Grid Search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0da667",
   "metadata": {},
   "source": [
    "### What challenges did you face while tuning the hyperparameters, and what actions did you take to address those challenges?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe8149e",
   "metadata": {},
   "source": [
    "There were not as many challenges tuning the hyperparamters, one of them was making sure that the dataset was properly prepared for the models. Narrowing down the ranges was easier this time as I just used the same tuning methods as the previous models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f26daac",
   "metadata": {},
   "source": [
    "### How many hours did you spend on hyperparameter tuning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8149d3",
   "metadata": {},
   "source": [
    "It took me around 6 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba4abb9",
   "metadata": {},
   "source": [
    "**Paste the hyperparameter tuning code below. You must show at least one hyperparameter tuning procedure.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efccf837",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69072146",
   "metadata": {},
   "source": [
    "### Decision Tree Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "002beb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "489\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state = 1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.get_depth())\n",
    "print(model.get_n_leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1251de7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "0.8448825483018594\n",
      "{'max_depth': 17, 'max_leaf_nodes': 202}\n"
     ]
    }
   ],
   "source": [
    "grid1 = {'max_depth': range(2,26,3), 'max_leaf_nodes': range(2,600,100)}\n",
    "\n",
    "gcv1 = GridSearchCV(model, grid1, cv = StratifiedKFold(n_splits = 10, shuffle=True, random_state=1), \n",
    "            scoring = 'accuracy', n_jobs = -1, verbose=1)\n",
    "\n",
    "gcv1.fit(X_train, y_train)\n",
    "\n",
    "print(gcv1.best_score_)\n",
    "print(gcv1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7a6725d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 66 candidates, totalling 660 fits\n",
      "0.8458869683967258\n",
      "{'max_depth': 18, 'max_leaf_nodes': 202}\n"
     ]
    }
   ],
   "source": [
    "grid2 = {'max_depth': range(2,23,2), 'max_leaf_nodes': range(2,300,50)}\n",
    "\n",
    "gcv2 = GridSearchCV(model, grid2, cv = StratifiedKFold(n_splits = 10, shuffle=True, random_state=1), \n",
    "            scoring = 'accuracy', n_jobs = -1, verbose=1)\n",
    "\n",
    "gcv2.fit(X_train, y_train)\n",
    "\n",
    "print(gcv2.best_score_)\n",
    "print(gcv2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b86e855c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 90 candidates, totalling 900 fits\n",
      "0.8466905852787407\n",
      "{'max_depth': 16, 'max_leaf_nodes': 177}\n"
     ]
    }
   ],
   "source": [
    "grid3 = {'max_depth': range(2,20,2), 'max_leaf_nodes': range(2,250,25)}\n",
    "\n",
    "gcv3 = GridSearchCV(model, grid3, cv = StratifiedKFold(n_splits = 10, shuffle=True, random_state=1), \n",
    "            scoring = 'accuracy', n_jobs = -1, verbose=1)\n",
    "\n",
    "gcv3.fit(X_train, y_train)\n",
    "\n",
    "print(gcv3.best_score_)\n",
    "print(gcv3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88fd2b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 90 candidates, totalling 900 fits\n",
      "0.8470929997656622\n",
      "{'max_depth': 16, 'max_leaf_nodes': 182}\n"
     ]
    }
   ],
   "source": [
    "grid4 = {'max_depth': range(2,19,2), 'max_leaf_nodes': range(2,200,25)}\n",
    "\n",
    "gcv4 = GridSearchCV(model, grid4, cv = StratifiedKFold(n_splits = 10, shuffle=True, random_state=1), \n",
    "            scoring = 'accuracy', n_jobs = -1, verbose=1)\n",
    "\n",
    "gcv4.fit(X_train, y_train)\n",
    "\n",
    "print(gcv4.best_score_)\n",
    "print(gcv4.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6e9fb19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "0.8476958134348258\n",
      "{'max_depth': 16, 'max_leaf_nodes': 186}\n"
     ]
    }
   ],
   "source": [
    "grid5 = {'max_depth': range(14,19,2), 'max_leaf_nodes': range(180,190,1)}\n",
    "\n",
    "gcv5 = GridSearchCV(model, grid5, cv = StratifiedKFold(n_splits = 10, shuffle=True, random_state=1), \n",
    "            scoring = 'accuracy', n_jobs = -1, verbose=1)\n",
    "\n",
    "gcv5.fit(X_train, y_train)\n",
    "\n",
    "print(gcv5.best_score_)\n",
    "print(gcv5.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294c275a",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e023a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_scaled = sc.transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "774bc6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.002310129700083158\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(-4, 1, 100)\n",
    "\n",
    "lasso = LassoCV(alphas=alphas, cv=10)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "print(\"Best alpha:\", lasso.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ad8c778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_preds = pd.DataFrame({\"Column\": X_train.columns, \"Coefficient\": lasso.coef_})\n",
    "insignificant_preds = lasso_preds.loc[lasso_preds['Coefficient']==0, 'Column']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "92c4c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cab6f821",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lasso = pd.get_dummies(train[preds], drop_first=True)\n",
    "X_test_lasso = pd.get_dummies(test[preds], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5806f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_preds = X_train_lasso.columns.drop(insignificant_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "17630308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sets with significant preds only\n",
    "X_train_lasso = X_train_lasso.loc[:, significant_preds]\n",
    "X_test_lasso = X_test_lasso.loc[:, significant_preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645aff7c",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8c824e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = DecisionTreeClassifier(random_state = 1, max_depth=16, max_leaf_nodes=186)\n",
    "ada_model = AdaBoostClassifier(estimator = base_model, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9bbe93d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle = True, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "66c3463f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 150 candidates, totalling 1500 fits\n",
      "0.8826581981850945\n",
      "{'estimator__max_depth': 10, 'learning_rate': 1, 'n_estimators': 145}\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ada_grid = {'estimator__max_depth': range(2,11,2),\n",
    "        'n_estimators': range(20,150,25),\n",
    "        'learning_rate': [0.001,0.01,0.1,1,10]\n",
    "       } \n",
    "\n",
    "ada_gcv = GridSearchCV(ada_model, ada_grid, cv = skf, scoring = 'accuracy', n_jobs = -1, verbose = 1)\n",
    "\n",
    "ada_gcv.fit(X_train_lasso, y_train)\n",
    "\n",
    "print(ada_gcv.best_score_)\n",
    "print(ada_gcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1ccabe46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "0.8850698568923582\n",
      "{'estimator__max_depth': 10, 'learning_rate': 1, 'n_estimators': 190}\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ada_grid1 = {'estimator__max_depth': range(8,11,2),\n",
    "        'n_estimators': range(120,200,10),\n",
    "        'learning_rate': [1,10]\n",
    "       } \n",
    "\n",
    "ada_gcv1 = GridSearchCV(ada_model, ada_grid1, cv = skf, scoring = 'accuracy', n_jobs = -1, verbose = 1)\n",
    "\n",
    "ada_gcv1.fit(X_train_lasso, y_train)\n",
    "\n",
    "print(ada_gcv1.best_score_)\n",
    "print(ada_gcv1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f5832fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=10,\n",
       "                                                    random_state=1),\n",
       "                   learning_rate=1, n_estimators=190, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=10,\n",
       "                                                    random_state=1),\n",
       "                   learning_rate=1, n_estimators=190, random_state=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=10, random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=10, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=10,\n",
       "                                                    random_state=1),\n",
       "                   learning_rate=1, n_estimators=190, random_state=1)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune threshold\n",
    "best_base_estimator = DecisionTreeClassifier(random_state = 1, max_depth = 10)\n",
    "best_ada_model = AdaBoostClassifier(estimator = best_base_estimator, random_state = 1, learning_rate = 1, \n",
    "                                    n_estimators = 190)\n",
    "\n",
    "y_probs = cross_val_predict(best_ada_model, X_train_lasso, y_train, cv=skf, method='predict_proba')[:,1]\n",
    "\n",
    "thresholds = np.arange(0,1.01,0.01)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for thr in thresholds:\n",
    "    # preds\n",
    "    y_preds = y_probs > thr \n",
    "    # accuracies\n",
    "    acc = accuracy_score(y_train, y_preds) \n",
    "    accuracies.append(acc) \n",
    "    \n",
    "np.array(accuracies).max() # best acc\n",
    "\n",
    "best_theshold = thresholds[np.array(accuracies).argmax()]\n",
    "print(best_theshold)\n",
    "\n",
    "best_ada_model.fit(X_train_lasso, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc357d",
   "metadata": {},
   "source": [
    "**Paste the optimal hyperparameter values below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "33497b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator__max_depth': 10, 'learning_rate': 1, 'n_estimators': 190}\n"
     ]
    }
   ],
   "source": [
    "print(ada_gcv1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e104de7",
   "metadata": {},
   "source": [
    "## 3) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a37864",
   "metadata": {},
   "source": [
    "Using the optimal model hyperparameters, train the model, and paste the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a6462944",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_base_estimator = DecisionTreeClassifier(random_state = 1, max_depth = 10)\n",
    "best_ada_model = AdaBoostClassifier(estimator = best_base_estimator, random_state = 1, learning_rate = 1, n_estimators = 190)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ad62a510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=10,\n",
       "                                                    random_state=1),\n",
       "                   learning_rate=1, n_estimators=190, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=10,\n",
       "                                                    random_state=1),\n",
       "                   learning_rate=1, n_estimators=190, random_state=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=10, random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=10, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=10,\n",
       "                                                    random_state=1),\n",
       "                   learning_rate=1, n_estimators=190, random_state=1)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ada_model.fit(X_train_lasso, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897d6954",
   "metadata": {},
   "source": [
    "## 4) Put any ad-hoc steps for further improving model accuracy\n",
    "For example, scaling up or scaling down the predictions, capping predictions, etc.\n",
    "\n",
    "Put code below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad509509",
   "metadata": {},
   "source": [
    "### implementing `host_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "34278a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = best_ada_model.predict_proba(X_test_lasso)[:,1] > best_theshold\n",
    "y_preds = y_preds.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6efceaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = test.id.values\n",
    "predicted = y_preds\n",
    "submission = pd.DataFrame({'id': id, 'predicted': predicted})\n",
    "submission = submission.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "12cefa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'host_id' to submission\n",
    "submission['host_id'] = test['host_id']\n",
    "\n",
    "# Use apply to replace 'predicted' based on 'host_id'\n",
    "submission['predicted'] = submission.apply(lambda row: train[train['host_id'] == row['host_id']]['host_is_superhost'].values[0] \n",
    "                                           if not train[train['host_id'] == row['host_id']].empty else row['predicted'], axis=1)\n",
    "\n",
    "# Drop 'host_id' from submission\n",
    "submission = submission.drop(columns=['host_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1c5d42",
   "metadata": {},
   "source": [
    "## 5) Export the predictions in the format required to submit on Kaggle\n",
    "Put code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "532468f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('boosting_classification_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
