{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2d08f12d",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Prediction problems: Report\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "    html-math-method: mathml \n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceeb191",
   "metadata": {},
   "source": [
    "# A) Prediction problem: Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1608757",
   "metadata": {},
   "source": [
    "## A.1) Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3999eccc",
   "metadata": {},
   "source": [
    "### Insight 1\n",
    "Given that this is a logistic regression problem, a good place to start was to see whether or not there is an imbalance in `host_is_superhost`. If there is, it could suggest that a tweak in threshold value is needed after we predict using the model. In this scenario, there is no inherent cost/outcome that we are concerned with, as we just want to accurately predict whether or not a host is a superhost. There is no drastic difference between the classes, so using 0.5 as the default threshold value is suitable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9017fc92",
   "metadata": {},
   "source": [
    "### Insight 2\n",
    "\n",
    "Similar to the linear regression problem, we can examine whether predictors being transformed, such as `number_of_reviews`, can be helpful for building the classifcation model. When we visualize the distributions by creating a histogram, we can see that some distributions are right-skewed, so using log transformations would be helpful in building a more accurate model.\n",
    "\n",
    "By the same vein, other similar variables such as `number_of_reviews_ltm` and `number_of_reviews_l30d` also have a similar right-skewed distribution, so they can also be transformed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944a2624",
   "metadata": {},
   "source": [
    "### Insight 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1d6358",
   "metadata": {},
   "source": [
    "I also went about doing exploratory data analysis by analyzing the overall correlations of the data set just like with the linear regression problem, particularly with respsect to `host_is_superhost`.  \n",
    "\n",
    "From the correlations, `log_reviews`, `log_reviews_ltm`, `host_total_listings_count`, and `has_missing` (status of whether an observation has any missing values) variables seem to be some of the highest correlated predictors with `host_is_superhost`. As such, this provided a good basis for these predictors to be included in the logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d691ac",
   "metadata": {},
   "source": [
    "## A.2) Data cleaning / preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaaaea5",
   "metadata": {},
   "source": [
    "Mention the data cleaning / preparation steps taken to prepare your data for developing the model. This may include imputing missing values, creating dummy variables, combining levels of categorical variable(s), discarding predictors that are not useful, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2410c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LassoCV, RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, roc_curve, auc, \\\n",
    "precision_score, recall_score, confusion_matrix, r2_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ede864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train_classification.csv')\n",
    "test = pd.read_csv('./test_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3c80a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['has_missing'] = train.isnull().any(axis=1).astype(int)\n",
    "test['has_missing'] = test.isnull().any(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c73f707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to categorize the property types\n",
    "def categorize_property(property_type):\n",
    "    if 'Entire' in property_type:\n",
    "        return 'Entire Home/Apartment'\n",
    "    elif 'Private' in property_type:\n",
    "        return 'Private Room'\n",
    "    elif 'Shared' in property_type:\n",
    "        return 'Shared Accommodation'\n",
    "    elif property_type in ['Room in hotel', 'Room in boutique hotel', 'Boat']:\n",
    "        return 'Specialty Accommodations'\n",
    "    else:\n",
    "        return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "481bc2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall function to clean training and test data\n",
    "def clean_data(df):\n",
    "    \n",
    "    if 'host_is_superhost' in df.columns:\n",
    "        df.host_is_superhost = df.host_is_superhost.replace({'t': 1, 'f': 0})\n",
    "        \n",
    "    # replace missing values of numeric variables wtih the median\n",
    "    numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "    df[numeric_columns] = df[numeric_columns].apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "    # replace missing values of categorical variables with the mode \n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    df[categorical_columns] = df[categorical_columns].fillna(df[categorical_columns].mode().iloc[0])\n",
    "    \n",
    "    # log transform response variable for training data and drop price\n",
    "    if 'price' in df.columns:\n",
    "        df['log_price'] = np.log(df['price'])\n",
    "    \n",
    "    # replace any 0 values to 1 so that it can go through log transformation\n",
    "    df['number_of_reviews'] = df['number_of_reviews'].replace(0, 1)\n",
    "    df['number_of_reviews_ltm'] = df['number_of_reviews_ltm'].replace(0, 1)\n",
    "    df['number_of_reviews_l30d'] = df['number_of_reviews_l30d'].replace(0, 1)\n",
    "\n",
    "    df['log_reviews'] = np.log(df.number_of_reviews)\n",
    "    df['log_reviews_ltm'] = np.log(df.number_of_reviews_ltm)\n",
    "    df['log_reviews_l30d'] = np.log(df.number_of_reviews_l30d)\n",
    "    \n",
    "    # calculate the number of days since the host became a host\n",
    "    df['host_since'] = pd.to_datetime(df['host_since'])\n",
    "    current_date = dt.now()\n",
    "    df['host_since_days'] = (current_date - df['host_since']).dt.days\n",
    "    \n",
    "    # calculate days since first/last review\n",
    "    df['first_review'] = pd.to_datetime(df['first_review'], errors='coerce')\n",
    "    df['last_review'] = pd.to_datetime(df['last_review'], errors='coerce')\n",
    "\n",
    "    df['first_review_days'] = (current_date - df['first_review']).dt.days\n",
    "    df['last_review_days'] = (current_date - df['last_review']).dt.days\n",
    "    \n",
    "    # make response_rate and acceptance_rate into numeric dtype\n",
    "    df['host_response_rate'] = df['host_response_rate'].str.rstrip('%').astype('float')\n",
    "    df['host_acceptance_rate'] = df['host_acceptance_rate'].str.rstrip('%').astype('float')\n",
    "    \n",
    "    # subgroup property_type\n",
    "    df['property_cats'] = df['property_type'].apply(categorize_property)\n",
    "    \n",
    "    # Extract numeric values from the 'bathrooms' column\n",
    "    df['bath_numeric'] = df['bathrooms_text'].str.extract('(\\d+\\.*\\d*)', expand=False).astype(float)\n",
    "\n",
    "    # Handle \"Half-bath\" by assigning a numeric value of 0.5\n",
    "    df['bath_numeric'] = df.apply(lambda row: 0.5 if 'half' in row['bathrooms_text'].lower() else row['bath_numeric'], axis=1)\n",
    "\n",
    "    # to binary\n",
    "    df.host_identity_verified = df.host_identity_verified.replace({'t': 1, 'f': 0})\n",
    "    df.host_has_profile_pic = df.host_has_profile_pic.replace({'t': 1, 'f': 0})\n",
    "    df.has_availability = df.has_availability.replace({'t': 1, 'f': 0})\n",
    "    df.instant_bookable = df.instant_bookable.replace({'t': 1, 'f': 0})\n",
    "    \n",
    "    # drop the columns modified\n",
    "    df.drop(columns = ['host_since', 'first_review', 'last_review', 'property_type', 'bathrooms_text', 'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd896455",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data(train)\n",
    "clean_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c46698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set response and predictors for scaling\n",
    "y_train = train.host_is_superhost\n",
    "X_train = train.drop(columns = ['id'])\n",
    "X_test = test.drop(columns = ['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd58e2ad",
   "metadata": {},
   "source": [
    "## A.3) Developing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5962c2e",
   "metadata": {},
   "source": [
    "### Step 1: Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bea0351",
   "metadata": {},
   "source": [
    "As touched upon in the EDA section, there were some variables that were identified to be more suitable for a log transformation due to having a right-skewed distribution. The variables that ended up getting log transformed were `number_of_reviews` and the other review variables.\n",
    "\n",
    "Just replacing the transformed log versions of the `review` variables instead of the original non-transformed predictors improved the model, which led me to keep them in the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0920287",
   "metadata": {},
   "source": [
    "### Step 2: Variable Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061e06d5",
   "metadata": {},
   "source": [
    "For this prediction problem, I also started out by using intuition and trial and error. `host_identity_verified` seems like it would do a decent job of predicting whether or not `host_is_superhost`, as it makes sense that superhosts generally have their identity verified to build their credibility with potential customers. The number of reviews that a host generates would also suggest if they are a superhost, as the more reviews they have the more it suggests that their listings are popular and credible. The rating values of those reviews, such as `review_scores_rating`, would also help indicate whether or not the host is a superhost, as they generally have more experience in catering towards the customers' experience. Furthermore, a host having higher `host_total_listings_count` and longer `host_since_days` would imply that they are highly experienced in hosting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920fb2f0",
   "metadata": {},
   "source": [
    "### Step 3: Significant Interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b5cc83",
   "metadata": {},
   "source": [
    "Similar to the variable selection step, intution and trial and error helped me in identifying signficant interactions that more accurately predict the `host_is_superhost` class. I intuitively thought that interactions between the quantity of reviews and the different review values would add more prediction power. For example, a listing could have some combination of high/low number and values of reviews. Having both predictors being high could help suggest a listing's host to be a superhost, and vice versa.\n",
    "\n",
    "Likewise, the interaction between `host_total_listings_count` and `host_since_days` makes sense in predicting `host_is_superhost`, as these two predictor variables give us information about how experienced a host is and how much time they have had to be reputable enough to become a superhost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7193fc7b",
   "metadata": {},
   "source": [
    "### Step 4: Using `host_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346eb4a6",
   "metadata": {},
   "source": [
    "Because we were also given the `host_id` in the training and test data sets, we can use that information to obtain the `host_is_superhost` class. We can get those from the training set and impute it into our test prediction if the `host_id` matches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c148744c",
   "metadata": {},
   "source": [
    "## A.4) Model equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ba3b92c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.472530\n",
      "         Iterations 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>host_is_superhost</td> <th>  No. Observations:  </th>  <td>  4977</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>       <th>  Df Residuals:      </th>  <td>  4965</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>        <th>  Df Model:          </th>  <td>    11</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 12 Mar 2024</td>  <th>  Pseudo R-squ.:     </th>  <td>0.3108</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>21:20:26</td>      <th>  Log-Likelihood:    </th> <td> -2351.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>        <th>  LL-Null:           </th> <td> -3412.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>     <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                      <td></td>                         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                 <td>   -5.6783</td> <td>    1.231</td> <td>   -4.614</td> <td> 0.000</td> <td>   -8.090</td> <td>   -3.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>host_identity_verified</th>                    <td>    0.6164</td> <td>    0.118</td> <td>    5.209</td> <td> 0.000</td> <td>    0.384</td> <td>    0.848</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_reviews</th>                               <td>    0.3279</td> <td>    0.385</td> <td>    0.852</td> <td> 0.394</td> <td>   -0.426</td> <td>    1.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>review_scores_location</th>                    <td>   -0.1006</td> <td>    0.197</td> <td>   -0.510</td> <td> 0.610</td> <td>   -0.488</td> <td>    0.286</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_reviews:review_scores_location</th>        <td>   -0.0631</td> <td>    0.080</td> <td>   -0.788</td> <td> 0.431</td> <td>   -0.220</td> <td>    0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_reviews_ltm</th>                           <td>  -11.4127</td> <td>    0.788</td> <td>  -14.482</td> <td> 0.000</td> <td>  -12.957</td> <td>   -9.868</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>review_scores_rating</th>                      <td>    0.9533</td> <td>    0.267</td> <td>    3.566</td> <td> 0.000</td> <td>    0.429</td> <td>    1.477</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_reviews_ltm:review_scores_rating</th>      <td>    2.4757</td> <td>    0.164</td> <td>   15.116</td> <td> 0.000</td> <td>    2.155</td> <td>    2.797</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>host_total_listings_count</th>                 <td>   -0.0038</td> <td>    0.001</td> <td>   -2.924</td> <td> 0.003</td> <td>   -0.006</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>host_since_days</th>                           <td> 7.519e-05</td> <td> 3.23e-05</td> <td>    2.331</td> <td> 0.020</td> <td>  1.2e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>host_total_listings_count:host_since_days</th> <td> 9.006e-07</td> <td> 3.54e-07</td> <td>    2.543</td> <td> 0.011</td> <td> 2.06e-07</td> <td> 1.59e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>has_missing</th>                               <td>   -0.3926</td> <td>    0.083</td> <td>   -4.735</td> <td> 0.000</td> <td>   -0.555</td> <td>   -0.230</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                                 & host\\_is\\_superhost & \\textbf{  No. Observations:  } &     4977    \\\\\n",
       "\\textbf{Model:}                                         &        Logit        & \\textbf{  Df Residuals:      } &     4965    \\\\\n",
       "\\textbf{Method:}                                        &         MLE         & \\textbf{  Df Model:          } &       11    \\\\\n",
       "\\textbf{Date:}                                          &   Tue, 12 Mar 2024  & \\textbf{  Pseudo R-squ.:     } &   0.3108    \\\\\n",
       "\\textbf{Time:}                                          &       21:20:26      & \\textbf{  Log-Likelihood:    } &   -2351.8   \\\\\n",
       "\\textbf{converged:}                                     &         True        & \\textbf{  LL-Null:           } &   -3412.4   \\\\\n",
       "\\textbf{Covariance Type:}                               &      nonrobust      & \\textbf{  LLR p-value:       } &    0.000    \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                        & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                      &      -5.6783  &        1.231     &    -4.614  &         0.000        &       -8.090    &       -3.266     \\\\\n",
       "\\textbf{host\\_identity\\_verified}                       &       0.6164  &        0.118     &     5.209  &         0.000        &        0.384    &        0.848     \\\\\n",
       "\\textbf{log\\_reviews}                                   &       0.3279  &        0.385     &     0.852  &         0.394        &       -0.426    &        1.082     \\\\\n",
       "\\textbf{review\\_scores\\_location}                       &      -0.1006  &        0.197     &    -0.510  &         0.610        &       -0.488    &        0.286     \\\\\n",
       "\\textbf{log\\_reviews:review\\_scores\\_location}          &      -0.0631  &        0.080     &    -0.788  &         0.431        &       -0.220    &        0.094     \\\\\n",
       "\\textbf{log\\_reviews\\_ltm}                              &     -11.4127  &        0.788     &   -14.482  &         0.000        &      -12.957    &       -9.868     \\\\\n",
       "\\textbf{review\\_scores\\_rating}                         &       0.9533  &        0.267     &     3.566  &         0.000        &        0.429    &        1.477     \\\\\n",
       "\\textbf{log\\_reviews\\_ltm:review\\_scores\\_rating}       &       2.4757  &        0.164     &    15.116  &         0.000        &        2.155    &        2.797     \\\\\n",
       "\\textbf{host\\_total\\_listings\\_count}                   &      -0.0038  &        0.001     &    -2.924  &         0.003        &       -0.006    &       -0.001     \\\\\n",
       "\\textbf{host\\_since\\_days}                              &    7.519e-05  &     3.23e-05     &     2.331  &         0.020        &      1.2e-05    &        0.000     \\\\\n",
       "\\textbf{host\\_total\\_listings\\_count:host\\_since\\_days} &    9.006e-07  &     3.54e-07     &     2.543  &         0.011        &     2.06e-07    &     1.59e-06     \\\\\n",
       "\\textbf{has\\_missing}                                   &      -0.3926  &        0.083     &    -4.735  &         0.000        &       -0.555    &       -0.230     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:      host_is_superhost   No. Observations:                 4977\n",
       "Model:                          Logit   Df Residuals:                     4965\n",
       "Method:                           MLE   Df Model:                           11\n",
       "Date:                Tue, 12 Mar 2024   Pseudo R-squ.:                  0.3108\n",
       "Time:                        21:20:26   Log-Likelihood:                -2351.8\n",
       "converged:                       True   LL-Null:                       -3412.4\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "=============================================================================================================\n",
       "                                                coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                    -5.6783      1.231     -4.614      0.000      -8.090      -3.266\n",
       "host_identity_verified                        0.6164      0.118      5.209      0.000       0.384       0.848\n",
       "log_reviews                                   0.3279      0.385      0.852      0.394      -0.426       1.082\n",
       "review_scores_location                       -0.1006      0.197     -0.510      0.610      -0.488       0.286\n",
       "log_reviews:review_scores_location           -0.0631      0.080     -0.788      0.431      -0.220       0.094\n",
       "log_reviews_ltm                             -11.4127      0.788    -14.482      0.000     -12.957      -9.868\n",
       "review_scores_rating                          0.9533      0.267      3.566      0.000       0.429       1.477\n",
       "log_reviews_ltm:review_scores_rating          2.4757      0.164     15.116      0.000       2.155       2.797\n",
       "host_total_listings_count                    -0.0038      0.001     -2.924      0.003      -0.006      -0.001\n",
       "host_since_days                            7.519e-05   3.23e-05      2.331      0.020     1.2e-05       0.000\n",
       "host_total_listings_count:host_since_days  9.006e-07   3.54e-07      2.543      0.011    2.06e-07    1.59e-06\n",
       "has_missing                                  -0.3926      0.083     -4.735      0.000      -0.555      -0.230\n",
       "=============================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smf.logit(formula = 'host_is_superhost~host_identity_verified+(log_reviews*review_scores_location)+(log_reviews_ltm*review_scores_rating)+(host_total_listings_count*host_since_days) + has_missing', data = train).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e72adf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(test) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "74ba7ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = test.id.values\n",
    "predicted = predicted.values\n",
    "submission = pd.DataFrame({'id': id, 'predicted': predicted})\n",
    "submission = submission.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "755665f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 'host_id' to submission\n",
    "submission['host_id'] = test['host_id']\n",
    "\n",
    "# use apply to replace 'predicted' based on 'host_id'\n",
    "submission['predicted'] = submission.apply(lambda row: train[train['host_id'] == row['host_id']]['host_is_superhost'].values[0] \n",
    "                                           if not train[train['host_id'] == row['host_id']].empty else row['predicted'], axis=1)\n",
    "\n",
    "# drop 'host_id' from submission\n",
    "submission = submission.drop(columns=['host_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b4ae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('classification_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
